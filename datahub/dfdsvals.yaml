# Values to deploy datahub with the helm chart
# See: https://github.com/acryldata/datahub-helm

elasticsearchSetupJob:
  extraEnvs:
  - name: USE_AWS_ELASTICSEARCH
    value: "true"

global:
  graph_service_impl: "elasticsearch"
  elasticsearch:
    # Secret
    host: "$(json.es_host.value)"
    port: "443"
    useSSL: true
    auth:
      # Secret
      username: "superuser"
      password:
        secretRef: "datahub"
        secretKey: "es-password"
  kafka:
    bootstrap:
      # Secret
      server: "$(KAFKA_BOOTSTRAP_SERVERS)"
    schemaregistry:
      # Secret
      url: "$(KAFKA_SCHEMAREGISTRY_URL)"
  sql:
    datasource:
      # Secret
      host: "$(json.db_host.value):$(json.db_port.value)"
      # Secret
      hostForMysqlClient: "$(json.db_host.value)"
      # Secret
      url: "jdbc:mysql://$(json.db_host.value):$(json.db_port.value)/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8&enabledTLSProtocols=TLSv1.2"
      # Secret
      username: "superuser"
      password:
        secretRef: "datahub"
        secretKey: "mysql-password"
  springKafkaConfigurationOverrides:
    security.protocol: SASL_SSL
    kafkastore.security.protocol: SASL_SSL
    sasl.mechanism: PLAIN
    sasl.username: "$(KAFKA_SASL_USERNAME)"
    sasl.password: "$(KAFKA_SASL_PASSWORD)"
    # Secret
    sasl.jaas.config:
      org.apache.kafka.common.security.plain.PlainLoginModule required
      username="$(KAFKA_SASL_USERNAME)" password="$(KAFKA_SASL_PASSWORD)";

datahub-frontend:
  resources:
    limits:
      cpu: "1"
      memory: 2Gi
    requests:
      cpu: "1"
      memory: 2Gi
  extraEnvs:
    - name: AUTH_OIDC_ENABLED
      value: "true"
    - name: AUTH_OIDC_CLIENT_ID
      value: "$(AUTH_OIDC_CLIENT_ID)"
    - name: AUTH_OIDC_CLIENT_SECRET
      value: "$(AUTH_OIDC_CLIENT_SECRET)"
    - name: AUTH_OIDC_DISCOVERY_URI
      value: "$(AUTH_OIDC_DISCOVERY_URI)"
    - name: AUTH_OIDC_BASE_URL
      value: "https://$(HOST)"

datahub-gms:
  resources:
    limits:
      cpu: "1"
      memory: 2Gi
    requests:
      cpu: "1"
      memory: 2Gi
  extraEnvs:
    # All Secret
    # Some of these are not needed, not clear which
    # See https://datahubproject.io/docs/how/kafka-config
    - name: METADATA_CHANGE_EVENT_NAME
      value: "$(METADATA_CHANGE_EVENT_NAME)"
    - name: METADATA_AUDIT_EVENT_NAME
      value: "$(METADATA_AUDIT_EVENT_NAME)"
    - name: FAILED_METADATA_CHANGE_EVENT_NAME
      value: "$(FAILED_METADATA_CHANGE_EVENT_NAME)"
    - name: KAFKA_MCE_TOPIC_NAME
      value: "$(KAFKA_MCE_TOPIC_NAME)"
    - name: KAFKA_FMCE_TOPIC_NAME
      value: "$(KAFKA_FMCE_TOPIC_NAME)"
    - name: KAFKA_TOPIC_NAME
      value: "$(KAFKA_TOPIC_NAME)"
    # New topics to replace all others, so the above can be deprecated in later versions
    # See https://datahubproject.io/docs/advanced/mcp-mcl/#topics
    - name: METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME
      value: "$(METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME)"
    - name: METADATA_CHANGE_LOG_TIMESERIES_TOPIC_NAME
      value: "$(METADATA_CHANGE_LOG_TIMESERIES_TOPIC_NAME)"
    - name: METADATA_CHANGE_PROPOSAL_TOPIC_NAME
      value: "$(METADATA_CHANGE_PROPOSAL_TOPIC_NAME)"
    - name: FAILED_METADATA_CHANGE_PROPOSAL_TOPIC_NAME
      value: "$(FAILED_METADATA_CHANGE_PROPOSAL_TOPIC_NAME)"

    # Consumer group IDs for consumers (must be different)
    - name: METADATA_AUDIT_EVENT_KAFKA_CONSUMER_GROUP_ID
      value: "$(METADATA_AUDIT_EVENT_KAFKA_CONSUMER_GROUP_ID)"
    - name: METADATA_CHANGE_EVENT_KAFKA_CONSUMER_GROUP_ID
      value: "$(METADATA_CHANGE_EVENT_KAFKA_CONSUMER_GROUP_ID)"

    # Analytics
    - name: DATAHUB_USAGE_EVENT_NAME
      value: "$(DATAHUB_USAGE_EVENT_TOPIC_NAME)"
    - name: DATAHUB_USAGE_EVENT_KAFKA_CONSUMER_GROUP_ID
      value: "$(DATAHUB_USAGE_EVENT_KAFKA_CONSUMER_GROUP_ID)"
    - name: METADATA_CHANGE_LOG_TOPIC_NAME
      value: "$(METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME)"
    - name: METADATA_CHANGE_LOG_LIMITED_TOPIC_NAME
      value: "$(METADATA_CHANGE_LOG_TIMESERIES_TOPIC_NAME)"
    - name: DATAHUB_TRACKING_TOPIC
      value: "$(DATAHUB_USAGE_EVENT_TOPIC_NAME)"
    - name: METADATA_CHANGE_LOG_KAFKA_CONSUMER_GROUP_ID
      value: "$(METADATA_CHANGE_LOG_KAFKA_CONSUMER_GROUP_ID)"
    - name: METADATA_CHANGE_PROPOSAL_KAFKA_CONSUMER_GROUP_ID
      value: "$(METADATA_CHANGE_PROPOSAL_KAFKA_CONSUMER_GROUP_ID)"
    - name: USE_AWS_ELASTICSEARCH
      value: "true"

kafkaSetupJob:
  enabled: false
